---
output:
  html_document
bibliography: ref.bib
---

# Batch correction 

```{r setup, echo=FALSE}
library(BiocStyle)
knitr::opts_chunk$set(message=FALSE, warning=FALSE, error=FALSE)
```

## Motivation

In large scRNA-seq projects, data generation is split across multiple batches due to logistical constraints.
However, the processing of different batches is often subject to uncontrollable differences,
e.g., small changes in incubation times, differences in reagent concentration/quality.
This may introduce systematic differences in the observed expression in cells from different batches, a.k.a., batch effects.
Batch effects are problematic as they can be major drivers of heterogeneity in the data,
masking relevant biological differences and complicating interpretation of the results.

Batch correction aims to remove batch effects to simplify downstream procedures like clustering.
The aim is to merge cells from different batches that represent the same biological subpopulation,
ensuring that they are assigned to the same cluster for easier interpretation.
Otherwise, cells may cluster by their batch of origin, which would be quite uninteresting.
Note that this step is quite different from the blocking discussed in most of the previous chapters,
as setting `block=` just instructs those functions to ignore the batch effect instead of actively removing it.

Historically, we used linear regression for batch correction of RNA-seq data [@ritchie2015limma;@leek2012sva].
(We can achieve the same effect with our PCA if we compute the components from the residuals, see Section \@ref(pca-block).)
However, this assumes that the composition of cell subpopulations is either known, and can be used as a covariate in the model;
or the composition is the same across batches, with a consistent batch effect in each subpopulation.
Such assumptions are usually inappropriate for single-cell studies.
Instead, we use bespoke methods for single-cell data [@haghverdi2018batch;@butler2018integrating;@lin2019scmerge] that do not require these strong assumptions^[
Well, to be more precise, they trade these obviously-wrong assumptions for a different set of less-obviously-wrong assumptions.].

## Using mutual nearest neighbors 

Mutual nearest neighbors (MNN) correction was one of the first batch correction methods dedicated to scRNA-seq data [@haghverdi2018batch]. 
For each cell in batch $B_1$, we search for the $k$ nearest neighbors in batch $B_2$ (for some small $k$, e.g., 10 - 20).
Similarly, for each cell in batch $B_2$, we search for the $k$ nearest neighbors in batch $B_1$.
We form an MNN pair between cells $x_1$ in batch $B_1$ and $x_2$ in batch $B_2$ if $x_1$ is $x_2$'s nearest neighbor and vice versa.
The assumption is that MNN pairs will (mostly) only form between $x_1$ and $x_2$ from the same biological subpopulation.
A subpopulation unique to batch $B_2$ will (hopefully) not be able to form MNN pairs to $B_1$,
as each cell in $B_1$ will be preoccupied with forming MNN pairs with cells from its matching subpopulation in $B_2$.
The difference between the cells in each MNN pair defines the direction and magnitude of the batch effect for its surrounding neighborhood,
allowing us to correct, e.g., $B_2$ to $B_1$ by subtracting that difference from each cell in $B_2$.
To demonstrate, let's use several PBMC datasets from 10X Genomics [@zheng2017massively]:

```{r}
library(TENxPBMCData)
sce.pbmc3k <- TENxPBMCData('pbmc3k')
sce.pbmc4k <- TENxPBMCData('pbmc4k')
sce.pbmc8k <- TENxPBMCData('pbmc8k')

# Finding a common set of genes across all batches to allow us to combine
# everything into a single object. This is only necessary if the different
# batches were processed with different genome annotations.
inter.pbmc <- Reduce(
    intersect,
    list(
        rownames(sce.pbmc3k),
        rownames(sce.pbmc4k),
        rownames(sce.pbmc8k)
    )
)
sce.pbmc <- combineCols(
    sce.pbmc3k[inter.pbmc,],
    sce.pbmc4k[inter.pbmc,],
    sce.pbmc8k[inter.pbmc,]
)
sce.pbmc$batch <- rep(
    c("3k", "4k", "8k"),
    c(ncol(sce.pbmc3k), ncol(sce.pbmc4k), ncol(sce.pbmc8k))
)

# For each dataset, TENxPBMCData loads the count data into the R session as a
# file-backed matrix, i.e., the "matrix" object is just a pointer to file
# containing the actual counts. For greater efficiency, we load the data into
# memory as a sparse matrix so that we don't have to repeatedly read from disk.
counts(sce.pbmc) <- as(counts(sce.pbmc), "dgCMatrix")

# Quality control, blocking on the batch of origin for each cell.
is.mito.pbmc <- grep("MT", rowData(sce.pbmc)$Symbol)
library(scrapper)
sce.qc.pbmc <- quickRnaQc.se(
    sce.pbmc,
    subsets=list(MT=is.mito.pbmc),
    block=sce.pbmc$batch
)
sce.qc.pbmc <- sce.pbmc[,sce.qc.pbmc$keep]

# Normalization, blocking on the batch of origin for each cell.
sce.norm.pbmc <- normalizeRnaCounts.se(
    sce.qc.pbmc,
    size.factors=sce.qc.pbmc$sum,
    block=sce.qc.pbmc$batch
)

# We now choose the top HVGs, with blocking.
sce.var.pbmc <- chooseRnaHvgs.se(
    sce.norm.pbmc, 
    block=sce.norm.pbmc$batch
)

# Running the PCA on the HVG submatrix, with blocking.
sce.pca.pbmc <- runPca.se(
    sce.var.pbmc,
    features=rowData(sce.var.pbmc)$hvg,
    number=25,
    block=sce.var.pbmc$batch
)
```

If we examine the distribution of cells without any batch correction, we observe some batch-specific substructure (Figure \@ref(fig:batch-pbmc-uncorrected)).
Such batch effects could have any number of causes -
biological differences in the underlying cell population between donors,
differences in the technology used for cell capture and/or sequencing,
or changes in the computational piplines for alignment and quantification.
Regardless of their origins, we consider these differences to be uninteresting as all batches are assaying the same PBMC population and should be replicates of each other. 

```{r batch-pbmc-uncorrected, fig.cap="$t$-SNE plot of the cells from the PBMC dataset, without any batch correction. Each cell is colored according to its batch of origin."}
sce.unc.tsne.pbmc <- runTsne.se(sce.pca.pbmc)
library(scater)
plotReducedDim(sce.unc.tsne.pbmc, "TSNE", colour_by="batch") + ggtitle("uncorrected")
```

To remove the batch effects, we use `correctMnn()` to apply MNN correction to the PC scores for all cells.
(As mentioned in the other chapters, we use PCs to leverage the compaction and denoising effects of the PCA on the HVGs.)
This yields a set of corrected scores that can be used in place of the original PCs in downstream analyses.
We observe greater intermingling between batches in Figure \@ref(fig:batch-pbmc-corrected), indicating that we have successfully mitigated the batch effect. 

```{r batch-pbmc-corrected, fig.cap="$t$-SNE plot of the cells from the PBMC dataset after MNN correction. Each cell is colored according to its batch of origin."}
sce.mnn.pbmc <- correctMnn.se(sce.pca.pbmc, sce.pca.pbmc$batch)
sce.mnn.tsne.pbmc <- runTsne.se(sce.mnn.pbmc, reddim.type="MNN")
plotReducedDim(sce.mnn.tsne.pbmc, "TSNE", colour_by="batch") + ggtitle("After correction")
```

Clustering on the corrected PCs ensures that cells from the same underlying population are assigned to the same cluster.
(We call this a "common clustering" as the definition of each cluster is the same in each batch.)
This avoids the formation of multiple clusters that represent the same cell type/state but are only separated due to batch effects.
Such redundant clusters are annoying to interpret as we have to (i) inspect more clusters to discover the same biology and (ii) match them up to each other for further analyses.
In addition, the correction increases the number of cells in any subpopulations that are shared across batches.
This provides some opportunities for improved resolution of rare subpopulations during the clustering step^[
Though this benefit is probably not that reliable as it assumes that the correction algorithm manages to preserve the rare subpopulations.
Indeed, both MNN correction and graph clustering are based on $k$-nearest neighbors with similar choices for $k$,
so if a cell type is too rare to form a separate cluster within a single batch, it's unlikely to form correct MNN pairs either.].

```{r}
sce.mnn.graph.pbmc <- clusterGraph.se(sce.mnn.pbmc, reddim.type="MNN")
```

Once we obtain a common clustering, a useful diagnostic measure is the distribution of cells across batches within each cluster.
If a cluster has contributions from multiple batches, it probably represents a cell type/state that is shared across those batches.
We expect our PBMC clusters to be more-or-less evenly distributed across batches as each batch is a replicate of the others.

```{r}
# This is a normalized matrix of cell counts for each group (row) and block
# (column). We divide each column by the number of cells in each batch to
# account for differences between batches. Then we divide by the row sums to
# get the distribution of cells across batches in each cluster.
cluster.batch.mnn.pbmc <- countGroupsByBlock(
    sce.mnn.graph.pbmc$clusters,
    sce.mnn.graph.pbmc$batch,
    normalize.groups=TRUE,
    normalize.block=TRUE
)
print(cluster.batch.mnn.pbmc, digits=2, zero.print=".")
```

If a cluster has no contribution from a batch, this either represents a unique subpopulation or it indicates that batch correction was not completely successful.
Indeed, clustering on the uncorrected PCs yields some batch-specific clusters in the PBMC data.
These are unlikely to represent unique types/states given that the batches should be replicates.

```{r}
sce.unc.graph.pbmc <- clusterGraph.se(sce.pca.pbmc)
cluster.batch.unc.pbmc <- countGroupsByBlock(
    sce.unc.graph.pbmc$clusters,
    sce.unc.graph.pbmc$batch,
    normalize.groups=TRUE,
    normalize.block=TRUE
)
print(cluster.batch.unc.pbmc, digits=2, zero.print=".")
```

```{r, echo=FALSE}
stopifnot(all(cluster.batch.mnn.pbmc != 0))
stopifnot(any(cluster.batch.unc.pbmc == 0))
```

Compared to linear regression, MNN correction does not assume that the population composition is the same or known beforehand.
It effectively learns the shared population structure via identification of MNN pairs and uses this information to estimate a local batch effect for subpopulation-specific correction.
However, MNN correction is not without its own assumptions:

- It requires some shared subpopulations between batches to encourage formation of the correct MNN pairs.
  Otherwise, if one batch contains B cells only and another batch contains T cells only, MNN pairs would form between the two cell types and the correction would merge them together.
  More generally, MNN correction becomes more robust with more shared subpopulations between batches.
  This implicitly reduces the risk of forming incorrect MNN pairs between unique subpopulations in each batch.
  Imagine we have one batch containing B cells and CD4^+^ T cells and another batch containing B cells and CD8^+^ T cells.
  MNN pairs would form correctly across batches for B cells, but they would also form between the CD4^+^ and CD8^+^ T cells as they are the closest available matches to each other.
  If our first batch also contained CD8^+^ T cells, they would match across batches and the CD4^+^ T cells would (correctly) not participate in any MNN pairs. 
- Any shared subpopulations should have more than $k$ cells in each batch to ensure that MNN pairs do not incorrectly form across different subpopulations.
  For example, let's say we have one batch that contains only T cells and another batch that contains B cells and fewer than 10 T cells.
  If we used $k = 10$, some MNN pairs would form between the T cells in the first batch and B cells in the second batch, which would be wrong.
  (That said, failure is not guaranteed for small populations - the example above would have worked out fine if B cells also existed in the first batch.
  It's just that the risk of incorrect MNN pairs is much higher when the subpopulation size drops below $k$.)
- For more subtle population structure, MNN correction assumes that the batch effect is orthogonal to the axes of biological variation.
  This is generally reasonable for batch effects caused by technical differences that are unrelated to biology - less so for biological differences.
  Say we're studying some kind of continuous biological variation, e.g., differentiation, and we have two batches that are replicates of each other. 
  We introduce a batch effect that is not orthogonal to the biological variation, e.g., because the second batch has higher baseline expression of the differentiation marker.
  MNN correction would be slightly incorrect as it preserves that the non-orthogonal component of the batch effect (Figure \@ref(fig:batch-activity-example)).

```{r batch-activity-example, echo=FALSE, fig.height=6, fig.width=10, fig.cap="Diagram of MNN correction when the batch effect is confounded with biological variation."} 
set.seed(999)
N <- 200
x1 <- runif(N) * 4 * pi
y1 <- sin(x1) * 0.5 + runif(N, -0.2, 0.2)
x2 <- runif(N) * 4 * pi
y2 <- sin(x2) * 0.5 + runif(N, -0.2, 0.2)

par(mar=c(0, 0, 0, 0))
plot(0, 0, type="n",xlim=c(0, 13 * pi), ylim=c(-3, 7), axes=FALSE, xlab="", ylab="")
points(x1, y1, col="blue")
text(4 * pi, 0, pos=4, "Batch 1", col="blue", font=3)
points(x2 + 2 * pi, y2 + 5, col="red")
text(4 * pi, 5.6, pos=3, "Batch 2", col="red", font=3)

arrows(0, -2, pi, -2, lwd=2, length=0.1)
text(pi, -2, "Axis of biological variation\n(e.g., differentiation status)", pos=4)
slope <- 5 / (2 * pi)
arrows(1, slope + 1, 4 / slope, 5, lwd=2, length=0.1)
text(4 / slope, 5, pos=3, "Batch\neffect")

for (x in c(2, 2.5, 3, 3.5, 4) * pi) {
    arrows(x, sin(x) * 0.5 - 0.5 + 5, x, sin(x) * 0.5 + 0.5, length = 0.1, lty= 2, code=3)
}
text(4 * pi, 2.5, pos=4, "MNN pairs")

right.shift <- 7 * pi
text(right.shift, 6, "What we want, i.e., the true correction", font=2, pos=4)
x.combined <- c(x1, x2)
y.combined <- c(y1, y2)
colors <- rep(c("blue", "red"), c(length(x1), length(x2)))
shuffle <- sample(length(colors))
points(x.combined[shuffle] + right.shift, y.combined[shuffle] + 4, col=colors[shuffle])

text(right.shift, 1, "What we get from MNN correction", font=2, pos=4)
x.combined <- c(x1, x2 + 2 * pi)
y.combined <- c(y1, y2)
colors <- rep(c("blue", "red"), c(length(x1), length(x2)))
shuffle <- sample(length(colors))
points(x.combined[shuffle] + right.shift, y.combined[shuffle] - 1, col=colors[shuffle])
```

Violations of some of these assumptions might be tolerable, sometimes.
For example, we wouldn't lose too much sleep if monocytes and macrophages were merged together across batches...
but then again, maybe we would, if we were really interested in studying differentiation in that particular lineage.
In any case, it is best to treat batch-corrected data - and conclusions derived from it - with a grain of salt.
The various merging decisions made by the algorithm may or may not be sensible depending on our scientific question.

## What is a batch effect, anyway?

In this chapter's introduction, we defined batch effects in terms of technical differences that are obviously uninteresting.
However, certain biological differences are also uninteresting and can be treated as batch effects.
One example is the biological variability between replicate samples (e.g., donors, animals, cultures) from which the cells are extracted.
We are generally uninterested in systematic differences between samples, which might cause cells of the same type to form separate clusters based on their sample of origin.
In these replicated experiments, we might consider removing this sample-to-sample variability by treating each sample as a batch in `correctMnn.se()`.
Similarly, we could apply batch correction to any uninteresting categorical factor in our dataset, e.g., sex, genotype, cell cycle phase.
Admittedly, we're misusing the word "batch" here^[
A better name would be "block", which is what we use to describe uninteresting factors in the rest of the book.
But "block correction" sounds weird and crypto-related so we just decided to stick with "batch" in the chapter name.],
but we're already halfway into this chapter so let's just bear with it until the end.

Now, what happens if different samples contain cells from different experimental conditions?
Say we have two samples where one contains control cells and the other contains drug-treated cells.
If we applied MNN correction to the samples, any treatment-induced differential expression would be treated as a batch effect and removed. 
This behavior is both expected and desirable - by merging cells from both conditions, we only need to characterize population heterogeneity once for all cells. 
For example, we can use the corrected coordinates to define a common set of clusters across both treated and control samples.
This, in turn, allows us test for differences in expression or abundance of the same cell type/state between conditions (Section \@ref(multi-condition-analyses)).

It may seem distressing to some folks that a (very interesting!) biological difference between conditions is deliberately removed by batch correction.
However, this concern is largely misplaced as the corrected values are only ever used for defining common clusters and annotations.
Any differences between conditions will still be preserved in the results of Section \@ref(multi-condition-analyses).
The alternative strategy would be to cluster each condition separately and to attempt to identify matching clusters across conditions,
which is much less convenient (though not an inherently bad idea, see Section \@ref(regrets)).

## Using the corrected values

As previously mentioned, the batch-corrected values are typically used to quantify population heterogeneity in a common manner across batches.
Cluster 1 in batch $B_1$ is the same as cluster 1 in batch $B_2$ when clustering is performed on the corrected data.
We do not have to cluster each batch separately and then identify mappings between separate clusterings, 
which is time-consuming and might not even be possible when the clusters are not well-separated.
The same reasoning applies to other cell-based analyses like trajectory reconstruction.

For per-gene analyses, the corrected values are more difficult to interpret. 
The correction is not obliged to preserve relative differences in per-gene expression when aligning multiple batches.
In fact, the opposite is true - the correction must distort the expression profiles to merge batches together,
as any differences in expression between batches for the same subpopulation would be a batch effect.
Let's demonstrate using two pancreas datasets [@grun2016denovo;@muraro2016singlecell] that we'll consider as separate batches.

```{r}
library(scRNAseq)
sce.grun <- GrunPancreasData()
sce.muraro <- MuraroPancreasData()

# Taking the intersection of features for both endogenous genes...
inter.pancreas <- intersect(rownames(sce.grun), rownames(sce.muraro))
sce.grun <- sce.grun[inter.pancreas,]
sce.muraro <- sce.muraro[inter.pancreas,]

# And spike-ins, for completeness...
inter.ercc.pancreas <- intersect(rownames(altExp(sce.grun, "ERCC")), rownames(altExp(sce.muraro, "ERCC")))
altExp(sce.grun, "ERCC") <- altExp(sce.grun, "ERCC")[inter.ercc.pancreas,]
altExp(sce.muraro, "ERCC") <- altExp(sce.muraro, "ERCC")[inter.ercc.pancreas,]

# Before combining both datasets into a single SCE object. 
sce.pancreas <- combineCols(sce.grun, sce.muraro)
sce.pancreas$batch <- rep(c("grun", "muraro"), c(ncol(sce.grun), ncol(sce.muraro)))

# Quality control, blocking on the batch of origin for each cell. We don't
# have mitochondrial genes here so we'll use the spike-ins instead.
library(scrapper)
sce.qc.pancreas <- quickRnaQc.se(
    sce.pancreas,
    subsets=NULL,
    altexp.proportions="ERCC",
    block=sce.pancreas$batch
)
sce.qc.pancreas <- sce.qc.pancreas[,sce.qc.pancreas$keep]

# Normalization, blocking on the batch of origin for each cell.
sce.norm.pancreas <- normalizeRnaCounts.se(
    sce.qc.pancreas,
    size.factors=sce.qc.pancreas$sum,
    block=sce.qc.pancreas$batch
)

# We now choose the top HVGs, with blocking.
sce.var.pancreas <- chooseRnaHvgs.se(sce.norm.pancreas, block=sce.norm.pancreas$batch)

# Running the PCA on the HVG submatrix, with blocking.
sce.pca.pancreas <- runPca.se(
    sce.var.pancreas,
    features=rowData(sce.var.pancreas)$hvg,
    block=sce.var.pancreas$batch
)
```

We use `correctMnn()` to obtain MNN-corrected PCs for clustering and visualization.
Both batches contribute to each cluster and are intermingled in Figure \@ref(fig:batch-pancreas-corrected),
which is expected given that both datasets are measuring the same pancreatic cell types.

```{r batch-pancreas-corrected, fig.cap="$t$-SNE plot of the Grun and Muraro pancreas datasets after MNN correction. Each point is a cell, colored according to its assigned batch."}
sce.mnn.pancreas <- correctMnn.se(sce.pca.pancreas, sce.qc.pancreas$batch)
sce.nn.mnn.pancreas <- runAllNeighborSteps.se(sce.mnn.pancreas, reddim.type="MNN")

cluster.batch.mnn.pancreas <- countGroupsByBlock(
    sce.nn.mnn.pancreas$clusters,
    sce.nn.mnn.pancreas$batch,
    normalize.groups=TRUE,
    normalize.block=TRUE
)
print(cluster.batch.mnn.pancreas, digits=2, zero.print=".")

library(scater)
plotReducedDim(sce.nn.mnn.pancreas, "TSNE", colour_by="batch")
```

```{r, echo=FALSE}
# Check that there are indeed contirbutions from both batches to each cluster.
stopifnot(all(cluster.batch.mnn.pancreas / rowSums(cluster.batch.mnn.pancreas) > 0.01))
```

We recover "corrected expression values" for any given gene by multiplying the corrected PCs with the corresponding row of the rotation matrix.
This is effectively a low-rank approximation of our original log-expression matrix, but using the corrected coordinates for each cell.
Of particular interest is the _INS-IGF2_ gene, where MNN correction forces the expression profiles to be consistent between batches (Figure \@ref(fig:batch-corrected-insigf2)).
(As of time of writing, this involved eliminating the variability in _INS-IGF2_ across clusters in the Grun dataset to match the lack of expression in the Muraro dataset,
though the opposite outcome is equally possible, i.e., introducing non-zero expression in the Muraro dataset to match that of the Grun dataset.)
From the perspective of the correction algorithm, this effect is intended as these differences between batches are part of the batch effect and must be removed.
However, if we relied the corrected expression values, we would draw misleading conclusions about the behavior of _INS-IGF2_ across batches.
For example, if one batch consisted of drug-treated patients and another batch was a control,
we would not detect any treatment-induced differential expression from the corrected expression values.

```{r batch-corrected-insigf2, fig.height=12, fig.width=8, fig.cap="Expression of _INS-IGF2_ across clusters in the combined Grun/Muraro pancreas dataset. Expression is quantified in terms of the log-normalized expression values (top panel), the reconstructed expression values with the uncorrected PCs (middle), and the reconstructed expression values with the MNN-corrected PCs (bottom)."}
current.insigf2 <- "INS-IGF2__chr11"
rotation.insigf2 <- metadata(sce.nn.mnn.pancreas)$PCA$rotation[current.insigf2,]
lowrank.unc.insigf2 <- reducedDim(sce.nn.mnn.pancreas, "PCA") %*% rotation.insigf2
lowrank.mnn.insigf2 <- reducedDim(sce.nn.mnn.pancreas, "MNN") %*% rotation.insigf2

gridExtra::grid.arrange(
    plotExpression(
        sce.nn.mnn.pancreas,
        x="clusters",
        features=current.insigf2,
        colour_by="clusters",
        other_fields="batch"
    ) + 
        facet_grid(~batch) +
        ggtitle("original expression"),
    plotXY(
        sce.nn.mnn.pancreas$clusters,
        lowrank.unc.insigf2,
        colour_by=sce.nn.mnn.pancreas$clusters,
        other_fields=list(batch=sce.nn.mnn.pancreas$batch)
    ) + 
        facet_grid(~batch) +
        ggtitle("reconstruction without correction"),
    plotXY(
        sce.nn.mnn.pancreas$clusters,
        lowrank.mnn.insigf2,
        colour_by=sce.nn.mnn.pancreas$clusters,
        other_fields=list(batch=sce.nn.mnn.pancreas$batch)
    ) +
        facet_grid(~batch) +
        ggtitle("reconstruction with correction"),
    ncol=1
)
```

For gene-based analyses, we recommend using the original log-expression values as these are easier to interpret.
Differences between batches should be handled by some other mechanism, e.g., blocking during marker detection (Figure \@ref(fig:batch-markers-pancreas), Section \@ref(marker-block)).
In the past decade, we have - perhaps once or twice - used the corrected values for visualization,
specifically to synchronize expression across all batches to the same color gradient in a $t$-SNE plot.
This was done purely for aesthetics and was probably not worth the extra hassle,
given that we had to check that the plot with the corrected values gave the same conclusions as the original expression values.

```{r batch-markers-pancreas, fig.cap="Distribution of log-expression values across clusters for the top marker in cluster 1 of the merged Grun/Muraro pancreas dataset. Each point is a cell and each facet is a batch."}
markers.pancreas <- scoreMarkers.se(
    sce.nn.mnn.pancreas,
    sce.nn.mnn.pancreas$clusters,
    block=sce.nn.mnn.pancreas$block
)

# Looking at the top markers for cluster 1.
chosen.markers.pancreas <- markers.pancreas[["1"]]
previewMarkers(chosen.markers.pancreas)

plotExpression(
    sce.nn.mnn.pancreas,
    x="clusters",
    features=rownames(chosen.markers.pancreas)[1],
    colour_by="clusters",
    other_fields="batch"
) + facet_grid(~batch)
```

## Multi-condition analyses

### Differential expression

The most interesting scRNA-seq datasets consist of multiple samples across different conditions, e.g., treated and untreated.
Once we have a common definition of clusters across all our samples, we can test for differences between conditions for each cluster.
In effect, we treat the scRNA-seq data as a kind of _in silico_ "super-FACS" -
FACS^[Fluorescence-activtated cell sorting, duh.] is used to experimentally isolate cell types of interest before bulk RNA-seq or quantifying abundance,
and now we do the same with scRNA-seq but our putative cell types are defined by clustering instead.
To illustrate, we'll pull out some pancreas data generated from normal donors and patients with type II diabetes [@segerstolpe2016singlecell]:

```{r}
library(scRNAseq)
sce.seger <- SegerstolpePancreasData()
table(sce.seger$individual, sce.seger$disease)
```

Happily enough, the authors provided cell type labels so we'll use those directly instead of going through the hassle of defining clusters ourselves.
We compute "pseudo-bulk" expression profiles [@tung2017batch] by summing counts together for all cells with the same combination of cell type and sample.
As their name suggests, these pseudo-bulk profiles are intended to mimic bulk RNA-seq data so that they can be analyzed with existing DE workflows, e.g., `r Biocpkg("edgeR")`, `voom()`.
We use the sum of counts for several reasons:

- Larger counts are more amenable to analysis workflows designed for bulk RNA-seq data.
  Normalization is more straightforward and certain statistical approximations are more accurate 
  e.g., the saddlepoint approximation for quasi-likelihood methods or normality for linear models.
- Collapsing cells into samples reflects the fact that our biological replication occurs at the sample level [@lun2017overcoming].
  Each sample is represented no more than once for each condition, avoiding problems from unmodelled correlations between samples. 
  Supplying the per-cell counts directly to a bulk RNA-seq workflow would imply that each cell is an independent biological replicate,
  which is not true from an experimental perspective.
  (A mixed effects model can handle this variance structure but involves [extra complexity](https://bbolker.github.io/mixedmodels-misc/glmmFAQ.html),
  typically for little benefit - see @crowell2019discovery.)
- Variance between cells within each sample is masked, provided it does not affect variance across (replicate) samples.
  This avoids penalizing DE genes that are not uniformly up- or down-regulated for all cells in all samples of one condition.
  Masking is generally desirable as DE genes - unlike marker genes - do not need to have low within-sample variance to be interesting,
  e.g., if the treatment effect is consistent across replicates but heterogeneous within each sample.

```{r}
pseudo.bulk.seger <- aggregateAcrossCells.se(sce.seger, colData(sce.seger)[,c("individual","cell type")])
pseudo.bulk.seger
colData(pseudo.bulk.seger)[,c("factor.individual", "factor.cell type", "counts")]
assay(pseudo.bulk.seger)[1:10,1:10] # sum of counts for each individual/cell-type combination
```

Once we have the pseudo-bulk count matrix, we test for differences between conditions (in this case, disease status) within each cell type.
Any DE analysis method that works with bulk RNA-seq data can be used - here, we'll be using `voom()` from the `r Biocpkg("limma")` package [@law2014voom].
We won't go into too much detail here as there is plentiful documentation elsewhere, e.g., see `limma::limmaUsersGuide()`.
Our only extra advice is to:

- Consider removing unreliable pseudo-bulk profiles with very few cells.
  The exact threshold depends on the dataset, the rarity of the cell type, the variance of the assay technology (e.g., UMIs versus reads),
  and whether the DE analysis supports downweighting of low-quality profiles.
  A good rule of thumb seems to be 10 cells [@crowell2019discovery].
- Perform a separate analysis for each cell type instead of cramming all cell types into the same design matrix.
  This protects against differences in the mean-variance relationship across cell types.
  It also ensures that any odd behavior for one cell type's does not affect inferences for the other cell types.
- Get used to higher variances and fewer DE genes compared to actual bulk RNA-seq data.
  The number of cells contributing to each pseudo-bulk profile is often orders of magnitude less than that used in bulk RNA-seq,
  so the latter will be a more precise assay of the population transcriptome.

We test for disease-associated DE genes in beta cells using `voom()` with additional weighting for sample quality.
Perhaps unsurprisingly, the top DE gene is _INS_.

```{r}
pseudo.beta.seger <- pseudo.bulk.seger[,which(pseudo.bulk.seger$`factor.cell type` == "beta cell")]

# We can have a look at the number of cells contributing to each profile, in
# case we want to remove low-abundance profiles.
pseudo.beta.seger$counts

library(edgeR)
y.beta.seger <- DGEList(assay(pseudo.beta.seger, "sums"), samples=as.data.frame(colData(pseudo.beta.seger)))

keep.beta.seger <- filterByExpr(y.beta.seger, group=y.beta.seger$samples$disease)
y.beta.seger <- y.beta.seger[keep.beta.seger,]
y.beta.seger <- normLibSizes(y.beta.seger)

design.beta.seger <- model.matrix(~disease, y.beta.seger$samples)
v.beta.seger <- voomWithQualityWeights(y.beta.seger, design.beta.seger)
fit.beta.seger <- lmFit(v.beta.seger)
fit.beta.seger <- eBayes(fit.beta.seger, robust=TRUE)

res.beta.seger <- topTable(fit.beta.seger, sort.by="p", n=Inf, coef=2)
head(res.beta.seger)
```

```{r, echo=FALSE}
stopifnot("INS" %in% head(res.beta.seger)$ID)
```

### Differential abundance

Another interesting analysis involves testing for differences in cell type abundance between conditions, i.e., differential abundance (DA).
We all know how immunologists love to create FACS plots showing some change in the percentages between treatments (e.g., Figure 1A of @richard2018tcell) -
now we can do the same kind of thing with scRNA-seq data.
For our pancreas dataset, we create a count matrix of the number of cells assigned to each cell type in each sample.
(If we didn't already have annotated cell types, we could instead consider using a tool like `r Biocpkg("miloR")`,
which performs a DA analysis without requiring explicit assignment of each cells to clusters.)

```{r}
ab.count.seger <- countGroupsByBlock(colData(sce.seger)[,"cell type"], colData(sce.seger)$individual)
ab.count.seger <- unclass(ab.count.seger) # get rid of the weird table class.
ab.count.seger
```

We then apply standard DA pipelines to see which cell types are affected by disease.
In particular, testing for DA is bread-and-butter stuff in the microbiome field,
so we'd recommend checking out some of their [best practices](https://microbiome.github.io/OMA/docs/devel/pages/differential_abundance.html).
Right now, though, this book is hard enough to compile without adding extra dependencies,
so we'll just re-use `r Biocpkg("edgeR")`'s statistical machinery to test for differences in the cell abundance matrix [@robinson2010edgeR]^[
With a hammer like `r Biocpkg("edgeR")`, everything kind of looks like a nail.].

```{r}
y.ab.seger <- DGEList(ab.count.seger)
y.ab.seger$samples$disease <- sce.seger$disease[match(colnames(y.ab.seger), sce.seger$individual)]

keep.ab.seger <- filterByExpr(y.ab.seger, group=y.ab.seger$samples$disease)
y.ab.seger <- y.ab.seger[keep.ab.seger,]

# If we don't normalize, our results will be affected by composition bias. But
# if we use TMM normalization, that would assume that most cell types do not
# have any change in their abundance. Hard to tell which one's worse here.

design.ab.seger <- model.matrix(~disease, y.ab.seger$samples)
fit.ab.seger <- glmQLFit(y.ab.seger, design.ab.seger)
res.ab.seger <- glmQLFTest(fit.ab.seger, coef=2)
topTags(res.ab.seger)
```

It's worth noting that DA and DE are two sides of the same coin as they are both based from the per-cell expression profiles.
Consider a scRNA-seq experiment involving two biological conditions with several shared cell types.
We focus on a cell type $X$ that is present in both conditions but contains some DE genes between conditions.
This leads to two possible outcomes:

1. The DE between conditions is strong enough to split $X$ into two separate clusters (say, $X_1$ and $X_2$) in expression space.
   This manifests as DA where $X_1$ is enriched in one condition and $X_2$ is enriched in the other condition.
2. The DE between conditions is not sufficient to split $X$ into two separate clusters, 
   e.g., because our batch correction algorithm identifies them as corresponding cell types and merges them together.
   Thus, the differences between conditions manifest as DE within the single cluster corresponding to $X$.

It is difficult to predict whether a difference between conditions will manifest as DE or DA.
For example, we might see DE for coarser clusters but DA for finer clusters.
We'd recommend performing both DE and DA analyses to ensure that we can catch either possibility.

## Some thoughts about replicates {#regrets}

Don't put too much faith in the results of DE/DA analyses derived from a common clustering.
These analyses do not capture the uncertainty in the clustering and its biological interpretation, which reduces confidence in the reproducibility of the results.
Say we discover significant DE/DA for a cell type in our dataset.
If an independent party were to repeat our experiment and analysis, would they be able to reach the same conclusion?
More specifically, would they be able to partition an equivalent cluster and assign the same cell type identity?
Weakly separated cell subtypes might not manifest as separate clusters in a new dataset,
or the ranking of markers might change in a manner that causes the analyst to assign a different biological identity.
We wouldn't know; we can't evaluate the reproducibility of our cell type annotations because we only did the clustering and interpretation once.

That said, there is a way to model this uncertainty - rarely used and tedious, but it can be done.
Consider a dataset that has multiple replicate samples for each of multiple conditions.
The strategy is as follows:

1. Analyze each sample independently, from quality control to identification of cell types/states from the clusters.
   If we were being very careful, we would blind and randomize samples across multiple analysts so that variances in human bias are also modelled during manual annotation of clusters^[
   Though this is so exceptionally laborious, it's probably not worth doing for anything other than a clinical trial.].
   Alternatively, we could use automated cell type annotation tools like `r Biocpkg("SingleR")`;
   these do not require any clustering and can be applied to each sample independently, but assume that our cell types of interest exist in the reference annotation.
2. Match corresponding cell types or states across samples.
   For manual annotation, we might consider using a controlled vocabulary of cell types/states to simplify this step, especially if multiple analysts are involved.
   A hierarchical cell type ontology is also useful, e.g., if we can't match two closely related subtypes, we can at least agree that they both match to the parent type.
   This step yields a common set of cell type/state identities across all samples, replacing the common clustering derived from the corrected PCs.
   As we are forced to be explicit about how cell types are matched across samples, we don't have to rely on the assumptions (and potential errors) of the correction algorithm.
3. Create a pseudo-bulk or cell abundance count matrix based on the annotated cell types/states from all samples.
   Any variability in the per-sample analysis will manifest as greater variance across replicates in these count matrices.
   For example, if a cell subtype is weakly defined, we may not be able to identify it consistently across replicates, increasing the variance in the cell type abundances.
   Similarly, if a subtype is poorly separated from its relatives, its cluster may occasionally include cells from neighboring subtypes, increasing the variance of the pseudo-bulk profiles.
   The increased variance is important as it properly reflects our uncertainty about the existence of the cell subtype itself.

In practice, this kind of analysis is pretty exhausting, especially for larger studies.
We recall only a handful of instances over the years because it's just too inconvenient. 
Besides, the incentives for reproducibility don't exist in the current scientific environment. 
Why should we do more work to introduce more variance and reduce the number of significant hits^[
Indeed, this is antithetical to the raison d'Ãªtre of single-cell genomics, which is to create publishable results.]?
We typically settle on a compromise between convenience and rigor,
where we still use a common clustering from corrected PCs but invest the extra time and resources into independent validation experiments
(see also suggestions in Section \@ref(marker-p-value-invalidity)).
As long as our conclusions can be validated, we can say that our preceding analyses were "exploratory" and give ourselves a pass for any statistical impropriety.

## Session information {-}

```{r}
sessionInfo()
```
