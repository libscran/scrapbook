# Quality Control

```{r, echo=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, error=FALSE)
```

## Motivation {#qc-motivation}

In a typical scRNA-seq dataset, some of the cells will be of "low quality" for one reason or another.
Perhaps the cells were damaged during dissociation, or maybe library preparation was not performed efficiently.
This usually manifests as cells with low total counts, few expressed genes and high mitochondrial/spike-in proportions.
Such low-quality libraries are problematic as they can contribute to misleading results in downstream analyses:

- They form their own distinct cluster(s), complicating interpretation of the results.
  Low-quality libraries generated from different cell types can cluster together based on similarities in the damage-induced expression profiles,
  creating artificial intermediate states or trajectories between otherwise distinct subpopulations. 
- They interfere with characterization of population heterogeneity during variance estimation or principal components analysis.
  The first few principal components will capture differences in quality rather than biology, reducing the effectiveness of dimensionality reduction.
  Similarly, genes with the largest variances will be driven by differences between low- and high-quality cells.
- Aggressive scaling normalization at small library sizes inflates the apparent expression of genes with non-zero counts in low-quality libraries.
  This contributes to the inflated variances and formation of artificial clusters.

To mitigate these problems, we remove the problematic cells before proceeding with the rest of our analysis.
This step is commonly referred to as quality control (QC) on the cells.
(We will use "library" and "cell" rather interchangeably here, though the distinction will become important when dealing with droplet-based data.)

## Common choices of QC metrics

We use several common QC metrics to identify low-quality cells based on their expression profiles.
These metrics are described below in terms of reads for SMART-seq2 data, 
but the same definitions apply to UMI data generated by other technologies like MARS-seq and droplet-based protocols.

- The library size is defined as the total sum of counts across all relevant features for each cell.
  Typically, the relevant features are the endogenous genes, in cases where other features (spike-ins, antibody-derived tags) are present.
  Cells with small library sizes are likely to be of low quality as the RNA has been lost at some point during library preparation,
  either due to cell lysis or inefficient cDNA capture and amplification.
- The number of expressed features in each cell is defined as the number of endogenous genes with non-zero counts for that cell.
  Any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured.
- The proportion of reads mapped to genes in the mitochondrial genome are indicative of poor-quality cells [@islam2014quantitative;@ilicic2016classification].
  The reasoning is that, in the presence of modest damage, perforations in the cell membrane permit efflux of cytoplasmic transcript molecules but are too small to allow mitochondria to escape.
  This leads to a relative enrichment of mitochondrial transcripts in libraries corresponding to damaged cells.
  (For single-nuclei RNA-seq experiments, high proportions are also useful as they can mark cells where the cytoplasm has not been successfully stripped.)
- The proportion of reads mapped to spike-in transcripts is calculated relative to the total count across all features (including spike-ins) for each cell.
  As the same amount of spike-in RNA should have been added to each cell, any enrichment in spike-in counts is symptomatic of loss of endogenous RNA.
  Thus, high proportions are indicative of poor-quality cells where endogenous RNA has been lost due to, e.g., partial cell lysis or RNA degradation during dissociation.

To demonstrate, we'll use a small scRNA-seq dataset from @lun2017assessing, which is provided with no prior QC steps.

```{r}
library(scRNAseq)
sce.416b <- LunSpikeInData("416b")
sce.416b

# Finding all the mitochondrial transcripts first.
location.416b <- rowRanges(sce.416b)
is.mito.416b <- which(any(seqnames(location.416b)=="MT"))
length(is.mito.416b)

# And then computing the QC metrics from our count matrix:
library(scrapper)
qc.metrics.416b <- computeRnaQcMetrics(counts(sce.416b), subsets=list(MT=is.mito.416b))
summary(qc.metrics.416b$sum)
summary(qc.metrics.416b$detected)
summary(qc.metrics.416b$subsets$MT)
```

Happily enough, this dataset also contains spike-in transcripts so we can compute the spike-in proportions as well.
These days, spike-ins are rare as they don't work well in high-throughput scRNA-seq protocols.
But `sce.416b` is a good old-fashioned plate-based dataset, so if we've got spike-in data, we might as well use it.
(Obviously, we can just skip this step for datasets where spike-in counts are not available.)

```{r}
# Fetching the spike-in data from the alternative experiment.
ercc.metrics.416b <- computeRnaQcMetrics(counts(altExp(sce.416b, "ERCC")), subsets=NULL)

# Adding the spike-in proportions to our QC results.
qc.metrics.416b$subsets$ERCC <- ercc.metrics.416b$sum / (qc.metrics.416b$sum + ercc.metrics.416b$sum)
summary(qc.metrics.416b$subsets$ERCC)
```

A key assumption here is that these QC metrics are independent of the biological state of each cell.
Poor values (e.g., low library sizes, high mitochondrial proportions) are presumed to be driven by technical factors rather than biological processes,
such that the removal of the corresponding cells will not misrepresent the biology in downstream analyses.
In heterogeneous datasets, this assumption is unlikely to be true:

- Some cell types have systematically less RNA content or more mitochondria (see Figure 3A of @germain2020pipecomp).
  For example, CD8+ T cells increase RNA synthesis upon stimulation while hepatocyptes contain more mitochondria to power their metabolic activities.
- Even if all cell types have the same total RNA content and mitochondria counts, certain cell types may be less amenable to the scRNA-seq protocol.
  The obvious example is that of neurons, which are easily damaged during dissociation and often have poorer values for the QC metrics.

Major violations of this assumption could result in the loss of entire cell types prior to downstream analysis.
We can check for such violations using diagnostic plots described in Section \@ref(quality-control-plots).

## Identifying low-quality cells

### With adaptive thresholds {#quality-control-outlier}

Here, we assume that most of our dataset consists of high-quality cells.
This is usually reasonable and can be experimentally supported in some situations by visually checking that the cells are intact, e.g., on the microwell plate.
We then identify cells that are outliers for the various QC metrics, based on the median absolute deviation (MAD) from the median value of each metric across all cells.
By default, we consider a value to be an outlier if it is more than 3 MADs from the median in the "problematic" direction.
This is loosely motivated by the fact that such a filter will retain 99% of non-outlier values that follow a normal distribution.

```{r}
qc.thresh.416b <- suggestRnaQcThresholds(qc.metrics.416b)
qc.thresh.416b
```

This function will compute a MAD-based outlier threshold for each metric.
For the library sizes and number of expressed genes, a lower threshold is defined after log-transforming the metrics.
This improves resolution at small values, avoids negative thresholds that would be meaningless for a non-negative metric,
and improves the normality of right-skewed distributions to justify the 99% rationale mentioned above.
(Note that only the MAD calculations are on the log-scale - the thresholds reported by `suggestRnaQcThresholds()` are always on the original scale.)
For the mitochondrial/spike-in proportions, an upper threshold is defined without any transformation to preserve resolution at large values.
We use these thresholds to filter for high-quality cells where the relevant metrics are above/below their respective lower/upper thresholds:

```{r}
qc.keep.416b <- filterRnaQcMetrics(qc.thresh.416b, qc.metrics.416b)
summary(qc.keep.416b)

# Subsetting our SingleCellExperiment to only retain high-quality
# cells in the downstream analysis steps.
sce.qc.416b <- sce.416b[,qc.keep.416b]
ncol(sce.qc.416b)
```

With this strategy, our thresholds adapt to both the location and spread of the distribution of values for a given metric.
This allows the QC procedure to adjust to changes in sequencing depth, cDNA capture efficiency, mitochondrial content, etc. without requiring any user intervention or prior experience.
The use of the MAD also improves robustness to dependencies between the QC metrics and the underlying biology, where some cell types have extreme QC metrics due to their biology.
A heterogeneous population should have higher variability in the metrics among high-quality cells, increasing the MAD and reducing the risk of inadvertently removing those cell types
(at the cost of reducing power to remove actual low-quality cells).

Keep in mind that the underlying assumption of a high-quality majority may not always be appropriate.
If most cells are of (unacceptably) low quality, the adaptive thresholds will fail as they cannot remove the majority of cells by definition. 
Of course, what is acceptable or not is rather context-dependent,
e.g., small library sizes for embryonic stem cells might be problematic but the same distribution would be perfectly satisfactory for a dataset of naive T cells. 
In practice, this assumption is convenient as it ensures that we always retain some cells for our downstream analyses.

### With fixed thresholds {#fixed-qc}

A simpler approach to identify low-quality cells involves applying fixed thresholds to the QC metrics.
For example, we might consider cells to be low quality if they have library sizes below 100000 reads;
express fewer than 5000 genes;
have spike-in proportions above 10%;
or have mitochondrial proportions above 10%.
We can use these thresholds to craft an equivalent list to `qc.thresh`, which can be used in `filterRnaQcMetrics()`:

```{r}
qc.thresh.fixed.416b <- list(
    sum = 1e5,
    detected = 5e3,
    subsets = c(MT = 0.1, ERCC = 0.1)
)

qc.keep.fixed.416b <- filterRnaQcMetrics(qc.thresh.fixed.416b, qc.metrics.416b)
summary(qc.keep.fixed.416b)
```

While intuitive, this strategy requires some experience to determine appropriate thresholds for each experimental protocol and biological system.
Thresholds for read count-based data are not applicable for UMI-based data, and vice versa.
Differences in mitochondrial activity or total RNA content require constant adjustment of the mitochondrial and spike-in thresholds, respectively, for different biological systems.
Even with the same protocol and system, the appropriate threshold can vary between runs due to fluctuations in cDNA capture efficiency and sequencing depth per cell.

## Creating diagnostic plots {#quality-control-plots}

It's often a good idea to inspect the distributions of QC metrics (Figure \@ref(fig:qc-dist-416b)) to identify possible problems.
In the most ideal case, we would see normal distributions that would justify the 3 MAD threshold used in outlier detection.
A large proportion of cells in another mode suggests that the QC metrics might be correlated with some biological state, potentially leading to the loss of distinct cell types during filtering;
or that there were inconsistencies with library preparation for a subset of cells, which is not uncommon in plate-based protocols.

```{r qc-dist-416b, fig.asp=1, fig.wide=TRUE, fig.cap="Distribution of QC metrics in the 416B dataset. Each point represents a cell and is colored according to whether it was retained after QC filtering. Dashed lines represent thresholds for each metric."}
# Adding the QC results to the SingleCellExperiment's colData,
# so that we can create pretty plots with scater.
sce.416b$sum <- qc.metrics.416b$sum
sce.416b$detected <- qc.metrics.416b$detected
sce.416b$MT_proportion <- qc.metrics.416b$subsets$MT
sce.416b$ERCC_proportion <- qc.metrics.416b$subsets$ERCC
sce.416b$keep <- qc.keep.416b

library(scater)
gridExtra::grid.arrange(
    plotColData(sce.416b, y="sum", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.416b$sum, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Total count"),
    plotColData(sce.416b, y="detected", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.416b$detected, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Detected features"),
    plotColData(sce.416b, y="MT_proportion", colour_by="keep") + 
        geom_hline(yintercept=qc.thresh.416b$subsets["MT"], linetype="dashed", color="red") +
        ggtitle("Mito prop"),
    plotColData(sce.416b, y="ERCC_proportion", colour_by="keep") + 
        geom_hline(yintercept=qc.thresh.416b$subsets["ERCC"], linetype="dashed", color="red") +
        ggtitle("ERCC prop"),
    ncol=2
)
```

For comparison, let's look at a different dataset with stronger biological heterogeneity [@grun2016denovo].
This dataset contains a mixture of pancreatic cell types from different donors, resulting in a more complex distribution for the metrics in Figure \@ref(fig:qc-dist-grun).
We might contemplate whether the clump of discarded cells corresponds to a genuine subpopulation,
though all things considered, they are probably just damaged cells and removing them is the correct choice. 

```{r qc-dist-grun, fig.asp=1, fig.wide=TRUE, fig.cap="Distribution of QC metrics in the Grun dataset. Each point represents a cell and is colored according to whether it was retained after QC filtering. Dashed lines represent thresholds for each metric."}
library(scRNAseq)
sce.grun <- GrunPancreasData()

# This dataset doesn't include any of the mitochondrial genes, unfortunately.
# But it does contain some nice ERCC spike-ins, so let's compute those proportions.
library(scrapper)
qc.metrics.grun <- computeRnaQcMetrics(counts(sce.grun), subsets=NULL)
ercc.metrics.grun <- computeRnaQcMetrics(counts(altExp(sce.grun, "ERCC")), subsets=NULL)
qc.metrics.grun$subsets$ERCC <- ercc.metrics.grun$sum / (ercc.metrics.grun$sum + qc.metrics.grun$sum)
qc.thresh.grun <- suggestRnaQcThresholds(qc.metrics.grun)
qc.keep.grun <- filterRnaQcMetrics(qc.thresh.grun, qc.metrics.grun)

sce.grun$sum <- qc.metrics.grun$sum
sce.grun$detected <- qc.metrics.grun$detected
sce.grun$ERCC_proportion <- qc.metrics.grun$subsets$ERCC
sce.grun$keep <- qc.keep.grun

library(scater)
gridExtra::grid.arrange(
    plotColData(sce.grun, y="sum", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.grun$sum, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Total count"),
    plotColData(sce.grun, y="detected", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.grun$detected, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Detected features"),
    plotColData(sce.grun, y="ERCC_proportion", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.grun$subsets["ERCC"], linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("ERCC proportion"),
    ncol=2
)
```

Another useful diagnostic involves comparing the proportion of mitochondrial counts against some of the other QC metrics.

- Libraries with both large total counts and large mitochondrial counts may represent high-quality cells that happen to be highly metabolically active (e.g., hepatocytes, muscle cells).
  A similar interpretation can be applied to libraries with high mitochondrial percentages and low spike-in percentages, if these are available. 
- Low-quality cells with small mitochondrial percentages, large spike-in percentages and small library sizes are likely to be stripped nuclei,
  i.e., they have been so extensively damaged that they have lost all cytoplasmic content.
  For single-nuclei studies, the stripped nuclei become the libraries of interest while the undamaged cells are of low quality.

We demonstrate on data from a larger experiment involving the mouse brain [@zeisel2015brain].
Figure \@ref(fig:qc-mito-zeisel) shows that the mitochondrial proportion is negatively correlated to the total count and positively correlated with the spike-in proportion.
This is consistent with a common underlying effect of cell damage and indicates that we are not removing metabolically active, undamaged cells.

```{r qc-mito-zeisel, fig.wide=TRUE, fig.cap="Percentage of UMIs assigned to mitochondrial transcripts in the Zeisel brain dataset, plotted against the total number of UMIs (left) or the ERCC proportions (right). Each point represents a cell and is colored according to whether it was considered high-quality."}
library(scRNAseq)
sce.zeisel <- ZeiselBrainData()
is.mito.zeisel <- rowData(sce.zeisel)$featureType=="mito"
summary(is.mito.zeisel)

# This dataset also contains spike-ins, so we might as well use them.
library(scrapper)
qc.metrics.zeisel <- computeRnaQcMetrics(counts(sce.zeisel), subsets=list(MT=is.mito.zeisel))
ercc.metrics.zeisel <- computeRnaQcMetrics(counts(altExp(sce.zeisel, "ERCC")), subsets=NULL)
qc.metrics.zeisel$subsets$ERCC <- ercc.metrics.zeisel$sum / (ercc.metrics.zeisel$sum + qc.metrics.zeisel$sum)
qc.thresh.zeisel <- suggestRnaQcThresholds(qc.metrics.zeisel)
qc.keep.zeisel <- filterRnaQcMetrics(qc.thresh.zeisel, qc.metrics.zeisel)

sce.zeisel$sum <- qc.metrics.zeisel$sum
sce.zeisel$detected <- qc.metrics.zeisel$detected
sce.zeisel$MT_proportion <- qc.metrics.zeisel$subsets$MT
sce.zeisel$ERCC_proportion <- qc.metrics.zeisel$subsets$ERCC
sce.zeisel$keep <- qc.keep.zeisel

library(scater)
gridExtra::grid.arrange(
    plotColData(sce.zeisel, x="sum", y="MT_proportion", colour_by="keep"),
    plotColData(sce.zeisel, x="ERCC_proportion", y="MT_proportion", colour_by="keep"),
    ncol=2
)
```

We can also check for inappropriate removal of cell types by comparing the expression profiles of the discarded and retained cells.
If the discarded pool is enriched for a certain cell type, we should observe increased expression of the corresponding marker genes.
To illustrate, we'll use a classic PBMC dataset from 10X Genomics [@zheng2017massively] where we perform some additional QC after cell calling.
Examination of the upregulated genes in Figure \@ref(fig:discardplotpbmc) reveals _PF4_, _PPBP_ and _SDPR_,
which (spoiler alert!) indicates that there is a platelet subpopulation that was removed by our QC filter.

```{r discardplotpbmc, fig.cap="Log-fold changes between discarded and retained cells in the PBMC dataset against the average abundance. Each point represents a gene, with platelet-related genes highlighted in red."}
# Loading in raw data from the 10X output files.
library(DropletTestFiles)
raw.path.10x <- getTestFile("tenx-2.1.0-pbmc4k/1.0.0/raw.tar.gz")
dir.path.10x <- file.path(tempdir(), "pbmc4k")
untar(raw.path.10x, exdir=dir.path.10x)

library(DropletUtils)
fname.10x <- file.path(dir.path.10x, "raw_gene_bc_matrices/GRCh38")
sce.10x <- read10xCounts(fname.10x, col.names=TRUE)

# Cell calling to distinguish real cells from empty droplets. Normally this
# would be handled by the CellRanger pipeline, but older versions of CellRanger
# would already remove interesting cells with low total counts before we could
# even make any QC decisions. So for the purposes of this example, we'll handle
# cell calling ourselves using the unfiltered count data. 
set.seed(100)
ed.10x <- emptyDrops(counts(sce.10x))
sce.10x <- sce.10x[,which(ed.10x$FDR <= 0.001)]

# Applying our default QC with outlier-based thresholds.
is.mito.10x <- grepl("^MT-", rowData(sce.10x)$Symbol)
qc.metrics.10x <- computeRnaQcMetrics(counts(sce.10x), subsets=list(MT=is.mito.10x))
qc.thresh.10x <- suggestRnaQcThresholds(qc.metrics.10x)
qc.keep.10x <- filterRnaQcMetrics(qc.thresh.10x, qc.metrics.10x)
summary(qc.keep.10x)

# Aggregating counts for cells that are either retained or discarded.
aggregate.10x <- scrapper::aggregateAcrossCells(counts(sce.10x), list(keep=ifelse(qc.keep.10x, "retain", "discard")))
colnames(aggregate.10x$sums) <- aggregate.10x$combinations$keep
head(aggregate.10x$sums)

# Computing log-fold changes between retained and discarded pools.
library(edgeR)
logged.10x <- cpm(aggregate.10x$sums, log=TRUE, prior.count=2)
logFC.10x <- logged.10x[,"discard"] - logged.10x[,"retain"]
abundance.10x <- rowMeans(logged.10x)

plot(abundance.10x, logFC.10x, xlab="Average abundance", ylab="Log-FC (discarded/retained)", pch=16, cex=0.5)
platelet <- match(c("PF4", "PPBP", "SDPR"), rowData(sce.10x)$Symbol)
points(abundance.10x[platelet], logFC.10x[platelet], col="red", pch=16)
```

```{r, echo=FALSE}
# Checking that we do, indeed, lose our platelets.
stopifnot(all(logFC.10x[platelet] > 3))
```

If we suspect that cell types have been incorrectly discarded by our QC procedure, the most direct solution is to relax the QC filters.
This is easily achieved for the outlier-based thresholds by increasing `num.mads=` in the `suggestRnaQcThresholds()` call.
Alternatively, we can disable filtering for particular metrics by setting the threshold to `Inf` or `-Inf` for upper and lower thresholds, respectively.
We might even think about skipping the filtering altogether^[
At this point, you might get the impression that the QC step involves many arbitrary and _ad hoc_ decisions.
That impression would mostly be correct.
Better get used to it, there's going to be a lot more of that in the rest of this book!],
as discussed in Section \@ref(qc-skip).

```{r}
# Effectively just filtering on the mitochondrial proportions.
qc.thresh.10x$sum <- -Inf
qc.thresh.10x$detected <- -Inf
qc.keep.10x.relaxed <- filterRnaQcMetrics(qc.thresh.10x, qc.metrics.10x)
summary(qc.keep.10x.relaxed)
```

## Considering experimental factors {#qc-batch}

More complex studies may involve batches of cells generated with different experimental parameters, e.g., sequencing depth.
In such cases, it makes little sense to compute medians and MADs from a mixture distribution containing samples from multiple batches.
For example, if the sequencing coverage is lower in one batch compared to the others, it will drag down the median and inflate the MAD.
This will reduce the suitability of the adaptive threshold for the other batches.

A possibly better approach is to compute an adaptive threshold separately for each batch, under the assumption that most cells in each batch are of high quality.
We illustrate using our 416B dataset again, which actually contains two experimental factors that we previously ignored:
the microwell plate in which each cell was processed, and whether the expression of a _CBFB-MYH11_ oncogene was induced by doxycycline treatment.
For the purposes of QC, we will consider each unique combination of these factors to be an experimental batch,
as both have the potential to alter the QC metrics, e.g., different sequencing coverage in each run, different RNA content after treatment.
Setting `block=` in `suggestRnaQcThresholds()` and `filterRnaQcMetrics()` yields a separate threshold for each batch (Figure \@ref(fig:qc-dist-416b-batch)).

```{r qc-dist-416b-batch, fig.asp=1, fig.wide=TRUE, fig.cap="Distribution of QC metrics in the 416B dataset, separated according to each cell's combination of experimental factors. Each point represents a cell and is colored according to whether it was retained after QC filtering. Dashed lines represent thresholds for each metric in each combination of factors."}
# Making a combined factor for easier reading.
plate.416b <- sce.416b$block # i.e., the plate of origin.
pheno.416b <- ifelse(sce.416b$phenotype == "wild type phenotype", "WT", "induced")
batch.416b <- paste0(pheno.416b, "-", plate.416b)

qc.thresh.batch.416b <- suggestRnaQcThresholds(qc.metrics.416b, block=batch.416b)
qc.thresh.batch.416b

qc.keep.batch.416b <- filterRnaQcMetrics(qc.thresh.batch.416b, qc.metrics.416b, block=batch.416b)
summary(qc.keep.batch.416b)

sce.416b$keep.batch <- qc.keep.batch.416b
sce.416b$combined.batch <- factor(batch.416b)

library(scater)
gridExtra::grid.arrange(
    plotColData(sce.416b, y="sum", x="combined.batch", colour_by="keep.batch") +
        scale_y_log10() +
        geom_segment(
            aes(x=as.numeric(batch) - 0.2, xend=as.numeric(batch) + 0.2, y=sum, yend=sum),
            data=data.frame(batch=factor(names(qc.thresh.batch.416b$sum)), sum=qc.thresh.batch.416b$sum),
            linetype="dashed",
            color="red"
        ) +
        ggtitle("Total count"),
    plotColData(sce.416b, y="detected", x="combined.batch", colour_by="keep.batch") +
        scale_y_log10() +
        geom_segment(
            aes(x=as.numeric(batch) - 0.2, xend=as.numeric(batch) + 0.2, y=detected, yend=detected),
            data=data.frame(batch=factor(names(qc.thresh.batch.416b$detected)), detected=qc.thresh.batch.416b$detected),
            linetype="dashed",
            color="red"
        ) +
        ggtitle("Detected features"),
    plotColData(sce.416b, y="MT_proportion", x="combined.batch", colour_by="keep.batch") + 
        geom_segment(
            aes(x=as.numeric(batch) - 0.2, xend=as.numeric(batch) + 0.2, y=prop, yend=prop),
            data=data.frame(batch=factor(names(qc.thresh.batch.416b$subsets$MT)), prop=qc.thresh.batch.416b$subsets$MT),
            linetype="dashed",
            color="red"
        ) +
        ggtitle("Mito prop"),
    plotColData(sce.416b, y="ERCC_proportion", x="combined.batch", colour_by="keep.batch") + 
        geom_segment(
            aes(x=as.numeric(batch) - 0.2, xend=as.numeric(batch) + 0.2, y=prop, yend=prop),
            data=data.frame(batch=factor(names(qc.thresh.batch.416b$subsets$ERCC)), prop=qc.thresh.batch.416b$subsets$ERCC),
            linetype="dashed",
            color="red"
        ) +
        ggtitle("ERCC prop"),
    ncol=2
)
```

That said, outlier detection will not be effective if a batch does not contain a majority of high-quality cells.
For example, some donors in the @grun2016denovo human pancreas dataset have higher ERCC proportions (Figure \@ref(fig:qc-plot-pancreas)), probably corresponding to damaged cells.
This inflates the median and MAD and reduces the effective of the QC filtering in the affected batches.

```{r qc-plot-pancreas, fig.wide=TRUE, fig.asp=0.5, fig.cap="Distribution of the proportion of ERCC transcripts in each donor of the Grun pancreas dataset. Each point represents a cell and is coloured according to whether it was considered high-quality across all metrics. Dashed lines represent donor-specific thresholds."}
qc.thresh.batch.grun <- suggestRnaQcThresholds(qc.metrics.grun, block=sce.grun$donor)
qc.thresh.batch.grun

qc.keep.batch.grun <- filterRnaQcMetrics(qc.thresh.batch.grun, qc.metrics.grun, block=sce.grun$donor)
summary(qc.keep.batch.grun)

sce.grun$keep.batch <- qc.keep.batch.grun
sce.grun$donor <- factor(sce.grun$donor)

plotColData(sce.grun, x="donor", y="ERCC_proportion", colour_by="keep.batch") +
    geom_segment(
        aes(x=as.numeric(donor) - 0.2, xend=as.numeric(donor) + 0.2, y=prop, yend=prop),
        data=data.frame(donor=factor(names(qc.thresh.batch.grun$subsets$ERCC)), prop=qc.thresh.batch.grun$subsets$ERCC),
        linetype="dashed",
        color="red"
    ) +
    ggtitle("ERCC prop")
```

For such problematic batches, some manual intervention may be necessary to set an appropriate threshold for the problematic batches.
A simple solution is to just derive a threshold from the other batches, e.g., by taking the average (Figure \@ref(fig:qc-plot-pancreas-fixed)).
This restores some semblance of QC to remove the bulk of damaged cells in the affected donors.
Hopefully, those cells really are damaged and we aren't accidentally removing a genuine subpopulation of small cells that are unique to those donors^[But who knows?].

```{r qc-plot-pancreas-fixed, fig.wide=TRUE, fig.asp=0.5, fig.cap="Distribution of the proportion of ERCC transcripts in each donor of the Grun pancreas dataset. Each point represents a cell and is coloured according to whether it was considered high-quality across all metrics. Dashed lines represent donor-specific thresholds, some of which are manually set for donors with a majority of low-quality cells."}
okay.donors <- c("D17", "D2", "D7")
bad.donors <- setdiff(unique(sce.grun$donor), okay.donors)

qc.thresh.batch.fixed.grun <- qc.thresh.batch.grun
qc.thresh.batch.fixed.grun$sum[bad.donors] <- mean(qc.thresh.batch.grun$sum[okay.donors])
qc.thresh.batch.fixed.grun$detected[bad.donors] <- mean(qc.thresh.batch.grun$detected[okay.donors])
qc.thresh.batch.fixed.grun$subsets$ERCC[bad.donors] <- mean(qc.thresh.batch.grun$subsets$ERCC[okay.donors])

qc.keep.batch.fixed.grun <- filterRnaQcMetrics(qc.thresh.batch.fixed.grun, qc.metrics.grun, block=sce.grun$donor)
summary(qc.keep.batch.fixed.grun)

sce.grun$keep.batch.fixed <- qc.keep.batch.fixed.grun
plotColData(sce.grun, x="donor", y="ERCC_proportion", colour_by="keep.batch.fixed") +
    geom_segment(
        aes(x=as.numeric(donor) - 0.2, xend=as.numeric(donor) + 0.2, y=prop, yend=prop),
        data=data.frame(donor=factor(names(qc.thresh.batch.fixed.grun$subsets$ERCC)), prop=qc.thresh.batch.fixed.grun$subsets$ERCC),
        linetype="dashed",
        color="red"
    ) +
    ggtitle("ERCC prop")
```

## Skipping quality control {#qc-skip}

If we don't want to risk discarding real cell types, we could simply mark the low-quality cells as such and retain them in the downstream analysis.
The aim here is to allow clusters of low-quality cells to form, and then to identify and ignore such clusters during interpretation of the results.
This approach avoids discarding cell types that have poor values for the QC metrics, deferring the decision on whether a cluster of such cells represents a genuine biological state.
So, in our 416B example, we would just continue with the unfiltered `sce.416b` for downstream analysis instead of using `sce.qc.416b`.

The downside is that it shifts the burden of QC to the manual interpretation of the clusters,
which is already a major bottleneck in scRNA-seq data analysis (Chapters \@ref(clustering) and \@ref(marker-detection)).
If we don't trust the QC metrics, we would have to distinguish between genuine cell types and low-quality cells based only on the cluster-specific marker genes...
but if we had good markers for low-quality cells, we would have already used them as QC metrics!
In practice, this usually becomes a time-consuming process of elimination whereby the clusters of low-quality cells are identified because they don't fit any other characterization.
Additionally, retention of low-quality cells may compromise the accuracy of other steps in the analysis (Section \@ref(qc-motivation)).

Personally, we^[That is to say, I.] suggest removing low-quality cells by default to avoid complications. 
This allows most of the population structure to be characterized with fewer concerns about its validity.
Once the initial analysis is done, and if there are any concerns about discarded cell types, a more thorough re-analysis can be performed where the low-quality cells are only marked.
This recovers cell types with low RNA content, high mitochondrial proportions, etc. that only need to be interpreted insofar as they "fill the gaps" in the initial analysis.

## Session Info {-}

```{r}
sessionInfo()
```
