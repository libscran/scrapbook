---
output:
  html_document
bibliography: ref.bib
---

# Quality Control

```{r, echo=FALSE}
knitr::opts_chunk$set(message=FALSE, warning=FALSE, error=FALSE)
```

## Motivation {#qc-motivation}

In a typical scRNA-seq dataset, some of the cells will be of "low quality" for one reason or another.
Perhaps the cells were damaged during dissociation, or maybe library preparation was not performed efficiently.
Such low-quality libraries are problematic as they can contribute to misleading results in downstream analyses:

- They form their own distinct cluster(s), complicating interpretation of the results.
  Low-quality libraries generated from different cell types can cluster together based on similarities in the damage-induced expression profiles,
  creating artificial intermediate states or trajectories between otherwise distinct subpopulations. 
- They interfere with quantification of population heterogeneity during variance estimation or principal components analysis.
  The first few principal components will capture differences in quality rather than biology, reducing the effectiveness of dimensionality reduction.
  Similarly, genes with the largest variances will be driven by differences between low- and high-quality cells.
- Many low-quality libraries have small total counts and are scaled up aggressively during normalization.
  This inflates the apparent expression of genes with non-zero counts in such libraries,
  which further contributes to inflated variances and formation of artificial clusters.

To mitigate these problems, we remove the problematic cells before proceeding with the rest of our analysis.
This step is commonly referred to as quality control (QC) on the cells.
(We will use "library" and "cell" interchangeably in this chapter;
the distinction is more important for droplet-based data, where some libraries may not contain cells.)

## Common choices of QC metrics

We use several common QC metrics to identify low-quality cells based on their expression profiles.
These metrics are described below in terms of reads for SMART-seq2 data, 
but the same definitions apply to UMI data generated by other technologies like MARS-seq and droplet-based protocols.

- The library size is defined as the total sum of counts across all relevant features for each cell.
  Typically, the relevant features are the endogenous genes, excluding other feature types (e.g., spike-ins) or modalities (e.g., antibody-derived tags).
  Cells with small library sizes are likely to be of low quality as the RNA has been lost at some point during library preparation,
  either due to cell lysis or inefficient cDNA capture and amplification.
- The number of expressed features in each cell is defined as the number of endogenous genes with non-zero counts for that cell.
  Any cell with very few expressed genes is likely to be of poor quality as the diverse transcript population has not been successfully captured.
- The proportion of reads mapped to genes in the mitochondrial genome is defined relative to the library size in each cell [@islam2014quantitative;@ilicic2016classification].
  The reasoning is that, in the presence of modest damage, perforations in the cell membrane permit efflux of cytoplasmic transcript molecules but are too small to allow mitochondria to escape.
  This leads to a relative enrichment of mitochondrial transcripts in libraries corresponding to damaged cells.
  (For single-nuclei RNA-seq experiments, high proportions are also useful as they represent cells where the cytoplasm has not been successfully stripped.)
- If spike-in transcripts were used in the experiment, the proportion of reads mapped to spike-ins is defined relative to the library size plus the total spike-in count in each cell.
  As the same amount of spike-in RNA should have been added to each cell, any enrichment in spike-in counts indicates that endogenous RNA was lost.
  Thus, high spike-in proportions are indicative of poor-quality cells where endogenous RNA has been lost due to, e.g., partial cell lysis or RNA degradation during dissociation.

To demonstrate, we'll use a small scRNA-seq dataset from @lun2017assessing, which is provided with no prior QC steps.
Happily enough, this dataset also contains spike-in transcripts so we can compute the spike-in proportions for each cell.
These days, spike-ins are rare as they don't work well in high-throughput scRNA-seq protocols;
but this 416B dataset was generated from a good old-fashioned plate-based protocol, so if we've got spike-in data, we might as well use it.

```{r}
library(scRNAseq)
sce.416b <- LunSpikeInData("416b")
sce.416b

# Finding all the mitochondrial transcripts first.
location.416b <- rowRanges(sce.416b)
is.mito.416b <- which(any(seqnames(location.416b)=="MT"))
length(is.mito.416b)

# And then computing the QC metrics from our count matrix.
library(scrapper)
sce.qc.416b <- quickRnaQc.se(
    sce.416b, 
    subsets=list(MT=is.mito.416b),
    altexp.proportions="ERCC" # omit this if no spike-ins are present.
)

summary(sce.qc.416b$sum)
summary(sce.qc.416b$detected)
summary(sce.qc.416b$subset.proportion.MT)
summary(sce.qc.416b$subset.proportion.ERCC)
```

A key assumption here is that these QC metrics are independent of the biological state of each cell.
Poor values (e.g., low library sizes, high mitochondrial proportions) are presumed to be driven by technical factors rather than biological processes,
such that the removal of the corresponding cells will not misrepresent the biology in downstream analyses.
In heterogeneous datasets, this assumption is unlikely to be true:

- Some cell types have systematically less RNA content or more mitochondria (see Figure 3A of @germain2020pipecomp).
  For example, CD8+ T cells increase RNA synthesis upon stimulation while hepatocyptes contain more mitochondria to power their metabolic activities.
- Even if all cell types have the same total RNA content and mitochondria counts, certain cell types may be less amenable to the scRNA-seq protocol.
  The obvious example is that of neurons, which are easily damaged during dissociation and often have poorer values for the QC metrics.

Major violations of this assumption could result in the loss of entire cell types prior to downstream analysis.
We can check for such violations using diagnostic plots described in Section \@ref(qc-plots),
but for now, let's just hope for the best and proceed through this chapter.

## Identifying low-quality cells

### With adaptive thresholds {#qc-outlier}

Once we have some QC metrics, we need to define thresholds with which we can separate low- and high-quality cells.
With the adaptive threshold strategy, we assume that most of our dataset consists of high-quality cells.
This is usually reasonable and can be experimentally verified in some situations, e.g., by visually checking that each cell is intact on a microwell plate.
We then identify cells that are outliers for any of the QC metrics, based on the median absolute deviation (MAD) from the median value of each metric across all cells.
By default, we consider a value to be an outlier if it is more than 3 MADs from the median in the "problematic" direction.
This is loosely motivated by the fact that such a filter will retain 99% of non-outlier values that follow a normal distribution.

```{r}
qc.thresh.416b <- metadata(sce.qc.416b)$qc$thresholds
qc.thresh.416b
```

This function computes a MAD-based outlier threshold for each metric.

- For the library sizes and number of expressed genes, a lower threshold is defined after log-transforming the metrics.
  This improves the normality of right-skewed distributions to justify the 99% rationale mentioned above.
  It also avoids defining a negative threshold that would be meaningless for a non-negative metric.
  Note that only the MAD calculations are on the log-scale - the thresholds reported in `qc.thresh.416b` are always on the original scale.
- For the mitochondrial/spike-in proportions, an upper threshold is defined without any transformation of the metrics.
  In particular, we do not log-transform as this would inflate the MAD by converting near-zero proportions to large negative log-values.

We apply these thresholds to filter for high-quality cells where the relevant metrics are above/below their respective lower/upper thresholds:

```{r}
# The 'keep' column in the colData is added by quickRnaQc.se() and indicates
# whether a cell should be kept after QC filtering.
summary(sce.qc.416b$keep)

# Subsetting our SingleCellExperiment to only retain high-quality
# cells in the downstream analysis steps.
sce.filt.416b <- sce.qc.416b[,sce.qc.416b$keep]
ncol(sce.filt.416b)
```

These outlier-based thresholds adapt to both the location and spread of the distribution of values for a given metric.
This enables the QC procedure to adjust to changes in sequencing depth, cDNA capture efficiency, mitochondrial content, etc. without any user intervention or prior experience.
The use of the MAD also improves robustness to dependencies between the QC metrics and the underlying biology, where some cell types have extreme QC metrics due to their biology.
A heterogeneous population should have higher variability in the metrics among high-quality cells, increasing the MAD and reducing the risk of inadvertently removing those cell types
(at the cost of reducing power to remove actual low-quality cells).

Keep in mind that the underlying assumption of a high-quality majority may not always be appropriate.
If most cells are of (unacceptably) low quality, the adaptive thresholds will fail as - by definition - they cannot remove the majority of cells. 
Of course, what is "acceptable" or not is rather context-dependent,
e.g., small library sizes for embryonic stem cells might be problematic but the same distribution would be perfectly satisfactory for a dataset of naive T cells. 
In practice, this assumption is convenient as it ensures that we always retain most cells for our downstream analyses.

### With fixed thresholds {#qc-fixed}

A simpler approach to identify low-quality cells involves applying fixed thresholds to the QC metrics.
For example, we might consider cells to be low quality if they have library sizes below 100000 reads;
express fewer than 5000 genes;
have spike-in proportions above 10%;
or have mitochondrial proportions above 10%.
We can supply these numbers directly to `quickRnaQc.se()` to force the function to use our thresholds:

```{r}
sce.fixed.416b <- quickRnaQc.se(
    sce.416b,
    subsets=list(MT=is.mito.416b),
    altexp.proportions="ERCC", 
    thresholds=list(
        sum = 1e5,
        detected = 5e3,
        subsets = c(MT = 0.1, ERCC = 0.1)
    )
)

summary(sce.fixed.416b$keep)
```

This strategy is intuitive but requires some experience to determine appropriate thresholds for each experimental protocol and biological system.
Thresholds for read count-based data are not applicable for UMI-based data, and vice versa.
Differences in mitochondrial activity or total RNA content require constant adjustment of the mitochondrial and spike-in thresholds, respectively, for different biological systems.
Even with the same protocol and system, the appropriate threshold can vary between runs due to fluctuations in cDNA capture efficiency and sequencing depth per cell.

## Creating diagnostic plots {#qc-plots}

It's prudent to inspect the distributions of QC metrics (Figure \@ref(fig:qc-dist-416b)) to identify possible problems.
In the most ideal case, we would see normal distributions that would justify the 3 MAD threshold used in outlier detection.
A large proportion of cells in another mode suggests that the QC metrics might be correlated with some biological state, potentially leading to the loss of distinct cell types during filtering;
or that there were inconsistencies with library preparation for a subset of cells, which is not uncommon in plate-based protocols.

```{r qc-dist-416b, fig.asp=1, fig.wide=TRUE, fig.cap="Distribution of QC metrics in the 416B dataset. Each point represents a cell and is colored according to whether it was retained after QC filtering. Dashed lines represent thresholds for each metric."}
library(scater)
gridExtra::grid.arrange(
    plotColData(sce.qc.416b, y="sum", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.416b$sum, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Total count"),
    plotColData(sce.qc.416b, y="detected", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.416b$detected, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Detected features"),
    plotColData(sce.qc.416b, y="subset.proportion.MT", colour_by="keep") + 
        geom_hline(yintercept=qc.thresh.416b$subset.proportion["MT"], linetype="dashed", color="red") +
        ggtitle("Mito prop"),
    plotColData(sce.qc.416b, y="subset.proportion.ERCC", colour_by="keep") + 
        geom_hline(yintercept=qc.thresh.416b$subset.proportion["ERCC"], linetype="dashed", color="red") +
        ggtitle("ERCC prop"),
    ncol=2
)
```

For comparison, let's look at a different dataset with stronger biological heterogeneity [@grun2016denovo].
This dataset contains a mixture of pancreatic cell types from different donors, resulting in a more complex distribution for the metrics in Figure \@ref(fig:qc-dist-grun).
We might contemplate whether the clump of discarded cells corresponds to a genuine subpopulation,
though all things considered, they are probably just damaged cells and removing them is the correct choice. 

```{r qc-dist-grun, fig.asp=0.4, fig.wide=TRUE, fig.cap="Distribution of QC metrics in the Grun dataset. Each point represents a cell and is colored according to whether it was retained after QC filtering. Dashed lines represent thresholds for each metric."}
library(scRNAseq)
sce.grun <- GrunPancreasData()

# This dataset doesn't include any of the mitochondrial genes, unfortunately.
# But it does contain some nice ERCC spike-ins, so let's compute those proportions.
library(scrapper)
sce.qc.grun <- quickRnaQc.se(sce.grun, subsets=list(), altexp.proportions="ERCC")
qc.thresh.grun <- metadata(sce.qc.grun)$qc$thresholds
qc.thresh.grun
summary(sce.qc.grun$keep)

library(scater)
gridExtra::grid.arrange(
    plotColData(sce.qc.grun, y="sum", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.grun$sum, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Total count"),
    plotColData(sce.qc.grun, y="detected", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.grun$detected, linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("Detected features"),
    plotColData(sce.qc.grun, y="subset.proportion.ERCC", colour_by="keep") +
        geom_hline(yintercept=qc.thresh.grun$subset.proportion["ERCC"], linetype="dashed", color="red") +
        scale_y_log10() +
        ggtitle("ERCC proportion"),
    ncol=3
)
```

Another useful diagnostic involves comparing the proportion of mitochondrial counts against some of the other QC metrics.

- Libraries with both large total counts and large mitochondrial counts may represent high-quality cells that happen to be highly metabolically active (e.g., hepatocytes, muscle cells).
  A similar interpretation can be applied to libraries with high mitochondrial percentages and low spike-in percentages, if these are available. 
- Low-quality cells with small mitochondrial percentages, large spike-in percentages and small library sizes are likely to be stripped nuclei,
  i.e., they have been so extensively damaged that they have lost all cytoplasmic content.
  For single-nuclei studies, the stripped nuclei become the libraries of interest while the undamaged cells are of low quality.

We demonstrate on data from a larger experiment involving the mouse brain [@zeisel2015brain].
Figure \@ref(fig:qc-mito-zeisel) shows that the mitochondrial proportion is negatively correlated to the total count and positively correlated with the spike-in proportion.
This is consistent with a common underlying effect of cell damage and indicates that we are not removing metabolically active, undamaged cells.

```{r qc-mito-zeisel, fig.asp=0.5, fig.wide=TRUE, fig.cap="Percentage of UMIs assigned to mitochondrial transcripts in the Zeisel brain dataset, plotted against the total number of UMIs (left) or the ERCC proportions (right). Each point represents a cell and is colored according to whether it was considered high-quality."}
library(scRNAseq)
sce.zeisel <- ZeiselBrainData()
is.mito.zeisel <- rowData(sce.zeisel)$featureType=="mito"
summary(is.mito.zeisel)

# This dataset also contains spike-ins, so we might as well use them.
library(scrapper)
sce.qc.zeisel <- quickRnaQc.se(sce.zeisel, subsets=list(MT=is.mito.zeisel), altexp.proportions="ERCC")
qc.thresh.zeisel <- metadata(sce.qc.zeisel)$qc$thresholds
qc.thresh.zeisel
summary(sce.qc.zeisel$keep)

library(scater)
gridExtra::grid.arrange(
    plotColData(sce.qc.zeisel, x="sum", y="subset.proportion.MT", colour_by="keep"),
    plotColData(sce.qc.zeisel, x="subset.proportion.ERCC", y="subset.proportion.MT", colour_by="keep"),
    ncol=2
)
```

We can also check for inappropriate removal of cell types by comparing the expression profiles of the discarded and retained cells.
If the discarded pool is enriched for a certain cell type, we should observe increased expression of the corresponding marker genes.
To illustrate, we'll use the classic PBMC dataset from 10X Genomics [@zheng2017massively] where we perform some additional QC after cell calling.
Examination of the upregulated genes in Figure \@ref(fig:discardplotpbmc) reveals _PF4_, _PPBP_ and _SDPR_,
which (spoiler alert!) indicates that there is a platelet subpopulation that was removed by our QC filter.

```{r discardplotpbmc, fig.cap="Log-fold changes between discarded and retained cells in the PBMC dataset against the average abundance. Each point represents a gene, with platelet-related genes highlighted in red."}
# Loading in raw data from the 10X output files.
library(DropletTestFiles)
raw.path.10x <- getTestFile("tenx-2.1.0-pbmc4k/1.0.0/raw.tar.gz")
dir.path.10x <- file.path(tempdir(), "pbmc4k")
untar(raw.path.10x, exdir=dir.path.10x)

library(DropletUtils)
fname.10x <- file.path(dir.path.10x, "raw_gene_bc_matrices/GRCh38")
sce.10x <- read10xCounts(fname.10x, col.names=TRUE)

# Cell calling to distinguish real cells from empty droplets. Normally this
# would be handled by the CellRanger pipeline, but older versions of CellRanger
# would already remove interesting cells with low total counts before we could
# even make any QC decisions. So for the purposes of this example, we'll handle
# cell calling ourselves using the unfiltered count data. 
set.seed(100)
ed.10x <- emptyDrops(counts(sce.10x))
sce.10x <- sce.10x[,which(ed.10x$FDR <= 0.001)]
sce.10x

# Applying our default QC with outlier-based thresholds.
is.mito.10x <- grepl("^MT-", rowData(sce.10x)$Symbol)
sce.qc.10x <- quickRnaQc.se(sce.10x, subsets=list(MT=is.mito.10x))

# Summing counts for the pools of retained or discarded cells.
aggregate.10x <- aggregateAcrossCells.se(
    sce.10x,
    list(status=ifelse(sce.qc.10x$keep, "retain", "discard"))
)
sums.10x <- assay(aggregate.10x, "sums")
colnames(sums.10x) <- aggregate.10x$factor.status
head(sums.10x)

# Computing log-fold changes between retained and discarded pools.
library(edgeR)
logged.10x <- cpm(sums.10x, log=TRUE, prior.count=2)
logFC.10x <- logged.10x[,"discard"] - logged.10x[,"retain"]
abundance.10x <- rowMeans(logged.10x)

plot(abundance.10x, logFC.10x, xlab="Average abundance", ylab="Log-FC (discarded/retained)", pch=16, cex=0.5)
platelet <- match(c("PF4", "PPBP", "SDPR"), rowData(sce.10x)$Symbol)
points(abundance.10x[platelet], logFC.10x[platelet], col="red", pch=16)
```

```{r, echo=FALSE}
# Checking that we do, indeed, lose our platelets.
stopifnot(all(logFC.10x[platelet] > 3))
```

If we suspect that cell types have been incorrectly discarded by our QC procedure, the most direct solution is to relax the QC filters.
This is easily achieved for the outlier-based thresholds by increasing `num.mads=` in the `quickRnaQc.se()` call.
Alternatively, we can disable filtering for particular metrics by setting the threshold to `Inf` or `-Inf` for upper and lower thresholds, respectively.
We might even think about skipping the filtering altogether^[
At this point, you might get the impression that the QC step involves many arbitrary and _ad hoc_ decisions.
That impression would mostly be correct.
Better get used to it, there's going to be a lot more of that in the rest of this book.],
as discussed in Section \@ref(qc-skip).

```{r}
# Effectively just filtering on the mitochondrial proportions.
relaxed.thresh.10x <- metadata(sce.qc.10x)$qc$thresholds
relaxed.thresh.10x$sum <- -Inf
relaxed.thresh.10x$detected <- -Inf
sce.relaxed.10x <- quickRnaQc.se(
    sce.10x,
    subsets=list(MT=is.mito.10x),
    thresholds=relaxed.thresh.10x
)
summary(sce.relaxed.10x$keep)
```

## Handling multiple batches {#qc-batch}

More complex studies may involve multiple batches of cells generated with different experimental parameters, e.g., sequencing depth.
In such cases, it makes little sense to compute medians and MADs from a mixture distribution containing samples from multiple batches.
For example, if the sequencing coverage is lower in one batch compared to the others, the median will be dragged down and the MAD will be inflated.
This will reduce the suitability of the adaptive threshold for each batch.

A possibly better approach is to compute an adaptive threshold separately for each batch, under the assumption that most cells in each batch are of high quality.
We illustrate using our 416B dataset again, which actually contains two experimental factors that we previously ignored:
the microwell plate in which each cell was processed, and whether the expression of a _CBFB-MYH11_ oncogene was induced by doxycycline treatment.
For the purposes of QC, we will consider each unique combination of these factors to be an experimental batch,
as both have the potential to alter the QC metrics, e.g., different sequencing coverage in each run or different RNA content after treatment.
Setting `block=` in `quickRnaQc.se()` yields a separate threshold for each batch (Figure \@ref(fig:qc-dist-416b-batch)),
which may be more appropriate than a common threshold across all batches.

```{r qc-dist-416b-batch, fig.asp=1, fig.wide=TRUE, fig.fullwidth=TRUE, fig.cap="Distribution of QC metrics in the 416B dataset, separated according to each cell's combination of experimental factors. Each point represents a cell and is colored according to whether it was retained after QC filtering. Dashed lines represent thresholds for each metric in each combination of factors."}
# Making a combined factor for easier reading.
plate.416b <- sce.416b$block # i.e., the plate of origin.
pheno.416b <- ifelse(sce.416b$phenotype == "wild type phenotype", "WT", "induced")
batch.416b <- paste0(pheno.416b, "-", plate.416b)

sce.batch.416b <- quickRnaQc.se(
    sce.416b,
    subsets=list(MT=is.mito.416b),
    altexp.proportions="ERCC",
    block=batch.416b
)
qc.thresh.batch.416b <- metadata(sce.batch.416b)$qc$thresholds
qc.thresh.batch.416b
summary(sce.batch.416b$keep)

library(scater)
sce.batch.416b$combined.batch <- batch.416b
gridExtra::grid.arrange(
    plotColData(sce.batch.416b, y="sum", x="combined.batch", colour_by="keep") +
        categoricalHlinesNamed(qc.thresh.batch.416b$sum, levels=NULL, linetype="dashed", color="red") +
        scale_x_discrete(guide = guide_axis(angle = 45)) +
        scale_y_log10() +
        ggtitle("Total count"),
    plotColData(sce.batch.416b, y="detected", x="combined.batch", colour_by="keep") +
        categoricalHlinesNamed(qc.thresh.batch.416b$detected, levels=NULL, linetype="dashed", color="red") +
        scale_x_discrete(guide = guide_axis(angle = 45)) +
        scale_y_log10() +
        ggtitle("Detected features"),
    plotColData(sce.batch.416b, y="subset.proportion.MT", x="combined.batch", colour_by="keep") + 
        categoricalHlinesNamed(qc.thresh.batch.416b$subset.proportion$MT, levels=NULL, linetype="dashed", color="red") +
        scale_x_discrete(guide = guide_axis(angle = 45)) +
        ggtitle("Mito proportion"),
    plotColData(sce.batch.416b, y="subset.proportion.ERCC", x="combined.batch", colour_by="keep") + 
        categoricalHlinesNamed(qc.thresh.batch.416b$subset.proportion$ERCC, levels=NULL, linetype="dashed", color="red") +
        scale_x_discrete(guide = guide_axis(angle = 45)) +
        ggtitle("ERCC proportion"),
    ncol=2
)
```

That said, outlier detection will not be effective if a batch does not contain a majority of high-quality cells.
For example, some donors in the @grun2016denovo human pancreas dataset have higher ERCC proportions (Figure \@ref(fig:qc-plot-pancreas)), probably corresponding to damaged cells.
This inflates the median and MAD and reduces the effectiveness of the QC filtering in those batches.

```{r qc-plot-pancreas, fig.wide=TRUE, fig.asp=0.5, fig.cap="Distribution of the proportion of ERCC transcripts in each donor of the Grun pancreas dataset. Each point represents a cell and is coloured according to whether it was considered high-quality across all metrics. Dashed lines represent donor-specific thresholds."}
sce.batch.grun <- quickRnaQc.se(
    sce.grun,
    subsets=list(),
    altexp.proportions="ERCC",
    block=sce.grun$donor
)
qc.thresh.batch.grun <- metadata(sce.batch.grun)$qc$thresholds
qc.thresh.batch.grun
summary(sce.batch.grun$keep)

plotColData(sce.batch.grun, x="donor", y="subset.proportion.ERCC", colour_by="keep") +
    categoricalHlinesNamed(qc.thresh.batch.grun$subset.proportion$ERCC, levels=NULL, linetype="dashed", color="red") +
    ggtitle("ERCC prop")
```

For such problematic batches, some manual intervention may be necessary to set an appropriate threshold. 
A simple solution is to just derive a threshold from the other batches, e.g., by taking the average (Figure \@ref(fig:qc-plot-pancreas-fixed)).
This restores some semblance of QC to remove the bulk of damaged cells in the affected donors.
Hopefully, those cells really are damaged and we aren't accidentally removing a real subpopulation of small cells that are unique to those donors^[But who knows?].

```{r qc-plot-pancreas-fixed, fig.wide=TRUE, fig.asp=0.5, fig.cap="Distribution of the proportion of ERCC transcripts in each donor of the Grun pancreas dataset. Each point represents a cell and is coloured according to whether it was considered high-quality across all metrics. Dashed lines represent donor-specific thresholds, some of which are manually set for donors with a majority of low-quality cells."}
okay.donors <- c("D17", "D2", "D7")
bad.donors <- setdiff(unique(sce.grun$donor), okay.donors)

qc.thresh.fixed.grun <- qc.thresh.batch.grun
qc.thresh.fixed.grun$sum[bad.donors] <- mean(qc.thresh.batch.grun$sum[okay.donors])
qc.thresh.fixed.grun$detected[bad.donors] <- mean(qc.thresh.batch.grun$detected[okay.donors])
qc.thresh.fixed.grun$subset.proportion$ERCC[bad.donors] <- mean(qc.thresh.batch.grun$subset.proportion$ERCC[okay.donors])

sce.fixed.grun <- quickRnaQc.se(
    sce.grun,
    subsets=list(),
    altexp.proportions="ERCC",
    block=sce.grun$donor,
    thresholds=qc.thresh.fixed.grun
)

plotColData(sce.fixed.grun, x="donor", y="subset.proportion.ERCC", colour_by="keep") +
    categoricalHlinesNamed(qc.thresh.fixed.grun$subset.proportion$ERCC, levels=NULL, linetype="dashed", color="red") +
    ggtitle("ERCC prop")
```

## Skipping quality control {#qc-skip}

If we don't want to risk discarding real cell types, we could simply mark the low-quality cells as such and retain them in the downstream analysis.
The aim here is to allow clusters of low-quality cells to form, and then to identify and ignore such clusters during interpretation of the results.
This approach avoids discarding cell types that have poor values for the QC metrics, deferring the decision on whether a cluster of such cells represents a genuine biological state.
So, in our 416B example, we would just continue with the unfiltered `sce.416b` for downstream analysis instead of using `sce.qc.416b`.

The downside is that it shifts the burden of QC to the manual interpretation of the clusters,
which is already a major bottleneck in scRNA-seq data analysis (Chapters \@ref(clustering) and \@ref(marker-detection)).
If we don't trust the QC metrics, we would have to distinguish between genuine cell types and low-quality cells based only on the cluster-specific marker genes...
but if we had good markers for low-quality cells, we would have already used them as QC metrics!
In practice, this usually becomes a time-consuming process of elimination whereby the clusters of low-quality cells are identified because they don't fit any other characterization.
Additionally, retention of low-quality cells may compromise the accuracy of other steps in the analysis, as discussed in Section \@ref(qc-motivation).

Personally, I'd suggest removing low-quality cells by default to avoid complications. 
This allows most of the population structure to be characterized with fewer concerns about its validity.
Once the initial analysis is done, and if there are any concerns about discarded cell types, a more thorough re-analysis can be performed where the low-quality cells are only marked.
This recovers cell types with low RNA content, high mitochondrial proportions, etc. that only need to be interpreted insofar as they "fill the gaps" in the initial analysis.

## Session Info {-}

```{r}
sessionInfo()
```
